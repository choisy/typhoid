---
title: "Classification workflow"
format:
  html:
    toc: true
editor: visual
editor_options: 
  chunk_output_type: console
---

```{r include = FALSE}
knitr::knit_hooks$set(
  margin = function(before, options, envir) {
    if (before) par(mgp = c(1.5, .5, 0), bty = "n",
                    plt = c(.105, .97, .13, .97))
    else NULL
  })

knitr::opts_chunk$set(margin     = TRUE,
                      fig.retina = 2,
                      fig.align  = "center")
```

## Limitations and suggestions

Limitations:

-   Small datasets
-   One of the datasets has very low prevalence 6%
-   The fever variable is different in the two datasets
-   We are trying to predict the result of culture when we do know that it depends on other causes that those in our variables (i.e. the quantity of blood used)
-   The durations of symptoms are questionable has it depends on the stage of the disease at which the patient sees the doctor

Suggestions:

-   Switch the role of the 2 datasets in terms of training and testing
-   Proceed in 2 steps: first build the best possible model that will used as a performance reference. Then build a clinical score and measure its performance by comparing with the best possible model

## Global parameters

The path to the data:

```{r}
data_path <- paste0(Sys.getenv("HOME"), "/Library/CloudStorage/",
                    "OneDrive-OxfordUniversityClinicalResearchUnit/",
                    "GitHub/choisy/typhoid/")
```

```{r include = FALSE}
make_path <- function(x) paste0(data_path, "cache/", x)
file_exists <- function(x) file.exists(make_path(x))
readRDS2 <- function(x) readRDS(make_path(x))
saveRDS2 <- function(object, file) saveRDS(object, make_path(file))
```


## Packages

Required packages:

```{r}
required_packages <- c("dplyr", "purrr", "rsample", "recipes", "themis", "parsnip",
                       "workflows", "yardstick", "tune", "finetune", "dials",
                       "randomForest")
```

Installing those that are not installed:

```{r}
to_inst <- required_packages[! required_packages %in% installed.packages()[,"Package"]]
if (length(to_inst)) install.packages(to_inst)
```

Loading some for interactive use:

```{r message = FALSE}
library(dplyr)
library(purrr)
library(rsample)
library(recipes)
library(themis)
library(parsnip)
library(workflows)
library(yardstick)
library(tune)
library(finetune)
library(dials)
```


## Utilitary functions

A function that reads a clean data set:

```{r}
read_clean_data <- function(file) readRDS(paste0(data_path, "clean_data/", file))
```

A function that transforms a logical vector into a factor vector (with the correct
number of levels):

```{r}
logical2factor <- function(x) factor(x, c("FALSE", "TRUE"))
```

This function builds an `rsplit` object by combining independent train and test data
sets:

```{r}
make_splits2 <- function(train, test) {
  n_train <- nrow(train)
  make_splits(list(analysis   = seq(n_train),
                   assessment = n_train + seq(nrow(test))),
              bind_rows(train, test))
}
```

Tuning the `collect_metrics()` function:

```{r}
collect_metrics2 <- function(...) {
  collect_metrics(...) |> 
    select(-.config, -.estimator)
}
```

Tuning the `last_fit()` function:

```{r}
last_fit2 <- function(wf, split, metrics) {
# the external validation:
  external <- wf |> 
    last_fit(split, metrics = metrics) |> 
    collect_metrics2() |> 
    select(-.metric)
    
# the internal cross-validation:
  wf |>
    fit_resamples(vfold_cv(training(split)), metrics = metrics) |> 
    collect_metrics2() |> 
    bind_cols(external) # to which we stick the external one.
}
```

## Reading the clean data

The Nepal dataset:

```{r}
nepal <- "nepal.rds" |> 
  read_clean_data() |> 
  mutate(across(c(cough, diarrhea, vomiting, abdominal_pain, constipation, headache),
                as.logical),
         across(c(age, platelets), as.numeric),
         across(fever, ~ .x > 2), ### isn't it the case anyway? 
         across(where(is.logical), logical2factor)) |> 
  select(-starts_with("score")) |> 
  select(-fever) |> 
  na.exclude()
```

The Cambodia and Bangladesh dataset:

```{r}
cambodia_bangladesh <- "cambodia_bangladesh.rds" |> 
  read_clean_data() |> 
  mutate(across(fever, ~ .x > 2),
         across(where(is.logical), logical2factor)) |> 
  select(-country) |> 
  select(-fever) |> 
  na.exclude()
```

Checking the consistency of the levels of the factors between the two datasets:

```{r}
get_levels <- function(x) x |>
  select(sex, IgM, CRP) |> 
  map(levels)

identical(get_levels(nepal), get_levels(cambodia_bangladesh))
rm(get_levels)
```

## The metric

We use the ROC AUC to measure the performance of the models:

```{r}
the_metric <- metric_set(roc_auc)
```

## The data splits

Let's consider the two of the two data sets:

```{r}
# train on Cambodia and Bangladesh and test on Nepal:
splits1 <- make_splits2(cambodia_bangladesh, nepal)
# train on Nepal and test on Cambodia and Bangladesh:
splits2 <- make_splits2(nepal, cambodia_bangladesh)
```

## The models

Let's consider 5 types of models:

```{r}
logistic_regression <- logistic_reg("classification", "glm")
logistic_regression_lasso <- logistic_reg("classification", "glmnet",
                                          penalty = tune())
logistic_regression_elasticnet <- logistic_reg("classification", "glmnet",
                                               penalty = tune(), mixture = tune())
random_forest <- rand_forest("classification", "randomForest")
random_forest_tuned <- rand_forest("classification", "randomForest",
                                   mtry = tune(), trees = tune(), min_n = tune())
```

## Functions to tune workflow

The function that builds a workflow without tuning:

```{r}
workflow_no_tune <- function(model, splits) {
  recipe(culture ~ ., training(splits)) |>
    step_unorder(all_ordered_predictors()) |> # adding this
    step_dummy(all_factor_predictors()) |> 
    step_smotenc(culture) |> 
    workflow(model)
}
```

The function that builds a workflow and tune it:

```{r}
workflow_tune <- function(model, split, size = 25, metric = the_metric,
                          mtry_range = c(1, 10)) {
  
  check_mtry <- function(x) {
    if (x$component[1] == "rand_forest") {
      if (any(map_chr(x$object[[1]]$range, class) == "call")) {
        return(update(x, mtry = mtry(mtry_range)))
      }
    }
    x
  }
    
  select_best2 <- function(...)
    select_best(..., metric = names(attributes(metric)$metrics))

  wkflw <- workflow_no_tune(model, split)
  
  grid <- wkflw |> 
    extract_parameter_set_dials() |> 
    check_mtry() |> 
    grid_space_filling(size = size)
  
  resamples <- vfold_cv(training(split))

  grid_search <- tune_grid(wkflw, resamples = resamples, grid = grid, metrics = metric)
    
  iterative_search <- safely(tune_bayes)(wkflw, resamples = resamples,
                                         initial = grid_search, metrics = metric)
  
  output <- list(grid_search = finalize_workflow(wkflw, select_best2(grid_search)))
  if (is.null(iterative_search$result)) return(output)
  output$iterative_search <- finalize_workflow(wkflw,
                                               select_best2(iterative_search$result))
  output
}
```

Wrappers around the above 2 functions to build and possibly tune several models at
once:

```{r}
workflows_tune <- function(models, split, size = 25, metric = the_metric,
                           mtry_range = c(1, 10)) {
  models |> 
    map(workflow_tune, split, size, metric, mtry_range) |> 
    unlist(FALSE) |> 
    unname()
}
```

and:

```{r}
workflows_no_tune <- function(models, splits) map(models, workflow_no_tune, splits)
```


## Models comparisons

Making all the workflows:

```{r}
make_workflows <- function(splits) {
  non_tuned_workflows <- workflows_no_tune(list(logistic_regression, random_forest),
                                           splits)
  
  tuned_workflows <- workflows_tune(list(logistic_regression_elasticnet,
                                         logistic_regression_lasso, random_forest_tuned),
                                    splits)
  
  unlist(list(non_tuned_workflows, tuned_workflows), FALSE)
}
```

Takes 9'42":

```{r eval = FALSE}
workflows <- map(list(splits1, splits2), make_workflows)
```

```{r include = FALSE}
if (file_exists("workflows.rds")) {
  workflows <- readRDS2("workflows.rds")
} else {
  workflows <- map(list(splits1, splits2), make_workflows)
  saveRDS2(workflows, "workflows.rds")
}
```

Takes 67":

```{r eval = FALSE}
workflows_performances <- map2(workflows, list(splits1, splits2),
                               ~ map(.x, last_fit2, .y, the_metric)) |> bind_rows()
```

```{r include = FALSE}
if (file_exists("workflows_performances.rds")) {
  workflows_performances <- readRDS2("workflows_performances.rds")
} else {
  workflows_performances <- map2(workflows, list(splits1, splits2),
                               ~ map(.x, last_fit2, .y, the_metric)) |> bind_rows()
  saveRDS2(workflows_performances, "workflows_performances.rds")
}
```

```{r include = FALSE, eval = FALSE}
if (file_exists("workflows_performances.rds")) {
  workflows_performances <- readRDS2("workflows_performances.rds")
} else {
  workflows_performances <- map2(workflows0,
                                 list(splits1, splits2),
                                 ~ .x |>
                                   unlist(FALSE) |>
                                   map(last_fit2, .y, the_metric)) |> bind_rows()
  saveRDS2(workflows_performances, "workflows_performances.rds")
}
```

```{r}
tibble(
    train  = rep(c("CamBan", "Nepal"), each = 8), 
    model  = rep(c("LR", "RF", rep(c("LS_EN", "LR_lasso", "RF_tuned"), each = 2)), 2),
    search = rep(c(rep(NA, 2), rep(c("grid", "iter"), 3)), 2)) |>
  bind_cols(workflows_performances)
```

```{r}
opar <- par(pty = "s")
with(workflows_performances, {
  min_val <- min(mean, .estimate)
  plot(mean, .estimate, col = rep(c(2, 4), each = 8), cex = 2,
       xlim = c(min_val, 1), ylim = c(min_val, 1),
       xlab = "mean training internal cross-validation", ylab = "testing dataset")
})
abline(0, 1)
box(bty = "o")
par(opar)
```

```{r}
opar <- par(pty = "s")
with(workflows_performances,
     plot(mean, .estimate, col = rep(c(2, 4), each = 8), cex = 2,
          xlim = 0:1, ylim = 0:1,
          xlab = "mean training internal cross-validation", ylab = "testing dataset"))
abline(0, 1)
box(bty = "o")
par(opar)
```


## Blood volume

```{r}
volumes_bangladesh <- readxl::read_excel(paste0(data_path,
                                                "raw_data/bangladesh_BC_volumes.xlsx")) |> 
  select(BC_Vol, BC_result) |> 
  mutate(across(BC_result, ~ .x == "Pos"))

volumes_cambodia <- readxl::read_excel(paste0(data_path,
                                              "raw_data/cambodia_BC_volumes.xlsx"))
```

```{r}
hist(volumes_bangladesh$BC_Vol)
```

```{r}
table(volumes_bangladesh$BC_result)
```

```{r}
with(volumes_bangladesh, plot(jitter(as.numeric(BC_result)), BC_Vol))
```

```{r}
volumes_bangladesh |> 
  filter(BC_result) |> 
  pull(BC_Vol) |> 
  density(from = 0) |> 
  plot(xlim = c(0, 20), ylim = c(0, .15), main = NA, axes = FALSE, ann = FALSE,
       col = 2, lwd = 2)

par(new = TRUE)

volumes_bangladesh |> 
  filter(! BC_result) |> 
  pull(BC_Vol) |> 
  density(from = 0) |> 
  plot(xlim = c(0, 20), ylim = c(0, .15), col = 4, lwd = 2, main = NA)

abline(v = 3.45)
```

```{r}
volumes_bangladesh |> 
  pull(BC_Vol) |> 
  na.exclude() |> 
  density(from = 0) |> 
  plot(xlim = c(0, 20), ylim = c(0, .15), col = 4, lwd = 2, main = NA,
       xlab = "volume", ylab = "density")

abline(v = 6.6)
```

```{r}
volumes_bangladesh |> 
  pull(BC_Vol) |> 
  na.exclude() |> 
  hist(n = 100, xlim = c(0, 16), col = 4, xlab = "volume", ylab = "frequency", main = NA)

par(new = TRUE)

volumes_bangladesh |> 
  pull(BC_Vol) |> 
  na.exclude() |> 
  density(from = 0) |> 
  plot(xlim = c(0, 16), ylim = c(0, .15), col = 2, lwd = 2, main = NA,
       xlab = "volume", ylab = "density", axes = FALSE, ann = FALSE)

abline(v = 6.6, col = 3, lwd = 2)
```


```{r}
rpart::rpart(BC_result ~ BC_Vol, volumes_bangladesh)
```

```{r}
f <- function(x) {
  volumes_bangladesh |> 
    filter(BC_Vol < x) |> 
    pull(BC_result) |> 
    mean()
}

xs <- seq(1, 15, .1)
plot(xs, map_dbl(xs, f), type = "l")
```

```{r}
volumes_bangladesh |> 
  arrange(BC_Vol)
```

```{r}
mod1 <- glm(BC_result ~ BC_Vol, binomial, volumes_bangladesh)
xs <- seq(0, 16, le = 512)
pred <- predict(mod1, data.frame(BC_Vol = xs), type = "response", se = TRUE)
plot(xs, pred$fit, type = "l", ylim = c(0, .3))
lines(xs, pred$fit - 1.96 * pred$se.fit, lty = 2)
lines(xs, pred$fit + 1.96 * pred$se.fit, lty = 2)
```

```{r}
mod2 <- glm(BC_result ~ BC_Vol + I(BC_Vol^2), binomial, volumes_bangladesh)
xs <- seq(0, 16, le = 512)
pred <- predict(mod2, data.frame(BC_Vol = xs), type = "response", se = TRUE)
plot(xs, pred$fit, type = "l", ylim = c(0, .3))
lines(xs, pred$fit - 1.96 * pred$se.fit, lty = 2)
lines(xs, pred$fit + 1.96 * pred$se.fit, lty = 2)

anova(mod1, mod2, test = "LRT")
```


```{r}
library(mgcv)
mod_gam <- mgcv::gam(BC_result ~ s(BC_Vol, bs = "bs", m = c(3, 2)), binomial, volumes_bangladesh, method = "REML")
pred_gam <- predict(mod_gam, data.frame(BC_Vol = xs), type = "response", se = TRUE)
plot(xs, pred_gam$fit, type = "n", ylim = c(0, .32), xlab = "volume",
     ylab = "probability of positive culture")

polygon(c(xs, rev(xs)),
        c(pred_gam$fit - 1.96 * pred$se.fit, rev(pred_gam$fit + 1.96 * pred$se.fit)),
        border = NA, col = adjustcolor(4, .2))
lines(xs, pred_gam$fit, col = 4, lwd = 2)

abline(v = 6.6, lwd = 2, col = 3)
```

```{r}
library(mgcv)
mod_gam <- mgcv::gam(BC_result ~ s(BC_Vol, bs = "bs", m = c(3, 2)), binomial,
                     volumes_bangladesh, method = "REML")
pred_gam <- predict(mod_gam, data.frame(BC_Vol = xs), type = "response", se = TRUE)
plot(xs, pred_gam$fit, type = "n", ylim = c(0, .32), xlab = "volume",
     ylab = "probability of positive culture")

polygon(c(xs, rev(xs)),
        c(pred_gam$fit - 1.96 * pred$se.fit, rev(pred_gam$fit + 1.96 * pred$se.fit)),
        border = NA, col = adjustcolor(4, .2))
lines(xs, pred_gam$fit, col = 4, lwd = 2)

abline(v = 6.6, lwd = 2, col = 3)
```








## Blood volumes 2

Reading the data:

```{r}
bv_bangladesh <- read_clean_data("bv_bangladesh.rds")
bv_cambodia <- read_clean_data("bv_cambodia.rds")
```

Combining the data:

```{r}
blood_volumes <- bind_rows(bv_bangladesh, bv_cambodia, .id = "country") |> 
  mutate(across(country, ~ c("Bangladesh", "Cambodia")[as.numeric(.x)]))
```

The percentage of missing values per variable and country:

```{r}
blood_volumes |> 
  group_by(country) |> 
  summarise(across(c(age, weight, volume), ~ sum(is.na(.x)) / length(.x)))
```

Randomizing the rows of the dataframe:

```{r}
blood_volumes_randomized <- blood_volumes[sample(nrow(blood_volumes)), ]
```

The function that plot variables of the randomized dataframe:

```{r}
colors <- c(2, 4)[factor(blood_volumes_randomized$country)]
units <- c(age = "(years)", weight = "(kg)", volume = "(mL)")

plot2 <- function(x, y, ...) {
  x <- substitute(x)
  y <- substitute(y)
  x_val <- deparse(x)
  y_val <- deparse(y)
  plot(eval(x, blood_volumes_randomized),
       eval(y, blood_volumes_randomized), col = colors,
       xlab = paste(x_val, units[x_val]), ylab = paste(y_val, units[y_val]), ...)
  legend("bottomright", pch = 1, col = c(2, 4), bty = "n",
         legend = c("Bangladesh", "Cambodia"))
}
```

Weight as a function of age:

```{r}
plot2(age, weight)
```

Volume as a function of age:

```{r}
plot2(age, volume)
abline(v = 20)
```

Volume as a function of weight:

```{r}
plot2(weight, volume)
```

The distribution of ages in Cambodia and Bangladesh:

```{r}
alpha <- .3
breaks <- 0:90

add_legend <- function() {
  legend("topright", fill = c(2, 4), bty = "n",
         legend = c("Bangladesh", "Cambodia"))
}

blood_volumes |> 
  filter(country == "Cambodia") |> 
  pull(age) |> 
  hist(breaks, main = NA, xlab = "age (years)", ylab = "number of samples",
       col = adjustcolor(4, alpha))

blood_volumes |> 
  filter(country == "Bangladesh") |> 
  pull(age) |>
  hist(breaks, col = adjustcolor(2, alpha), na.rm = TRUE, add = TRUE)

add_legend()
```

The distribution of volume values in Cambodia and Bangladesh:

```{r}
breaks <- seq(0, 16, .5)

blood_volumes |> 
  filter(country == "Cambodia") |> 
  pull(volume) |> 
  hist(breaks, main = NA, xlab = "volume (mL)", ylab = "number of samples",
       col = adjustcolor(4, alpha))

blood_volumes |> 
  filter(country == "Bangladesh") |> 
  pull(volume) |> 
  hist(breaks, col = adjustcolor(2, alpha), na.rm = TRUE, add = TRUE)

add_legend()
```

Model:

```{r}
model <- blood_volumes |> 
  filter(country == "Bangladesh") |> 
  select(-weight, -country) |> 
  na.exclude() |> 
  with(glm(culture ~ age * volume, binomial))

anova(model)
```

```{r}
processed <- blood_volumes |> 
  filter(country == "Bangladesh") |> 
  select(volume, culture) |> 
  na.exclude() |> 
  mutate(vol_cat = cut(volume, quantile(volume, seq(0, 1, .1)),
                       include.lowest = TRUE)) |>
  tidyr::separate(vol_cat, c("vol_lower", "vol_upper"), ",") |> 
  mutate(across(starts_with("vol_"), ~ .x |>
                  stringr::str_remove("\\(|\\[|\\]") |>
                  as.numeric())) |> 
  rowwise() |> 
  mutate(vol_mean = mean(c(vol_lower, vol_upper))) |> 
  ungroup() |>
  group_by(vol_mean) |> 
  mutate(prop     = list(prop.test(sum(culture), length(culture))),
         cult_est = purrr::map_dbl(prop, ~ .x$estimate),
         confint  = purrr::map(prop, ~ setNames(.x$conf.int,
                                                c("cult_lower", "cult_upper")))) |> 
  tidyr::unnest_wider(confint)
```

```{r}
with(processed, {
  plot(NA, xlim = c(0, max(vol_upper)), ylim = c(0, max(cult_upper)),
       xlab = "volume (mL)", ylab = "probability of culture positive")
  arrows(vol_mean, cult_lower, vol_mean, cult_upper, .1, 90, 3, col = 2, lwd = 2)
  points(vol_mean, cult_est, col = 2, pch = 19)
  abline(v = unique(c(vol_lower, vol_upper)), lty = 2, col = "grey")
})
```


```{r}
blood_volumes |> 
  filter(country == "Bangladesh") |> 
  select(age, culture)
```



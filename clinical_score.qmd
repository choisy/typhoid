---
title: "Random forest classification"
format: html
editor: visual
editor_options: 
  chunk_output_type: console
---

```{r include = FALSE}
knitr::opts_chunk$set(fig.retina = 2,
                      fig.align  = "center")
```


## Parameters

The path to the data folder:

```{r}
data_path <- paste0("/Users/MarcChoisy/Library/CloudStorage/",
                    "OneDrive-OxfordUniversityClinicalResearchUnit/",
                    "GitHub/choisy/typhoid/")
```


## Packages

The required packages:

```{r}
required_packages <- c("dplyr", "purrr", "stringr", "rsample", "glmnet", "glmnetUtils")
```

Making sure that the required packages are installed:

```{r}
to_inst <- required_packages[! required_packages %in% installed.packages()[,"Package"]]
if (length(to_inst)) install.packages(to_inst)
rm(required_packages, to_inst)
```

Loading some of these packages:

```{r message = FALSE}
library(dplyr)
library(purrr)
library(rsample)
library(glmnet)
library(glmnetUtils)
```


## Reading the clean data

The path to the data:

```{r}
nepal <- readRDS(paste0(data_path, "clean_data/nepal.rds"))
```


## Feature engineering

Nepal data set:

```{r}
nepal2 <- nepal |> 
  mutate(across(c(Cough, Diarrhoea, vomiting, Abdopain, Constipation, Headache,
                  Anorexia, Nausea, Typhoid_IgM), ~ .x > 0)) |> 
  na.exclude()
```

```{r}
nepal3 <- select(nepal2, BloodCSResult, Cough:Hepatomegaly)
```

```{r}
nepal3 |> 
  select(where(is.logical)) |> 
  map(table)
```


## Spliting the data

Let's create the train and test data sets:

```{r}
data_split <- initial_split(nepal3)
train_data <- training(data_split)
test_data <- testing(data_split)
```


## Some utilitary functions

```{r}
moving_average <- function(x, w = 20) {
  x |>
    seq_along() |> 
    map(~ tail(c(0, x), -.x)) |> 
    head(-w  + 1) |> 
    map(head, w) |> 
    map_dbl(mean)
}
```

```{r}
plot_smooth <- function(x, w, data = nepal3) {
  data[order(data[[x]]), ] |> 
    select({{ x }}, BloodCSResult) |> 
    map_dfc(moving_average, w) |> 
    plot(col = 4)
}
```

```{r}
confusion_matrix <- function(threshold) {
  nepal5 |> 
    mutate(across(points, ~ .x > threshold)) |> 
    table()
}
```

```{r}
specificity <- function(x) {
  x[1, 1] / sum(x[1, ])
}
```

```{r}
sensitivity <- function(x) {
  x[2, 2] / sum(x[2, ])
}
```

```{r}
accuracy <- function(x) {
  diag(x) / sum(x)
}
```

```{r}
j_index <- function(x) {
  specificity(x) + sensitivity(x) - 1
}
```

A function that converts a named vector of coefficient values into a named vector of
points corresponding to a clinical score:

```{r}
coef2scores <- function(x, n) {
  xmin <- min(x)
  xmax <- max(x)
  stepv <- min(diff(seq(xmin, xmax, le = n)))
  ubrks <- seq(xmin - stepv, xmax + stepv, le = n)
  cbrks <- ubrks - ubrks[which.min(abs(ubrks))]
  setNames(sort(c(-(1:sum(cbrks < 0)), 1:sum(cbrks > 0)))[as.integer(cut(x, cbrks))],
           stringr::str_remove(names(x), "TRUE"))
}
```

A function that computes the points from a data frame `df` of binary valued variable
and a vector `cscore` of clinical scores. The names of the data frame and the the
vector should be the same, although not necessarily in the same order.

```{r}
make_points <- function(df, cscore) {
  colSums(t(as.matrix(df)) * cscore[names(df)])
}
```


## Exploration of the effect of the continuous variables

```{r}
plot_smooth("OralTemperature", 120, nepal3)
plot_smooth("Pulse", 100, nepal3)
plot_smooth("OralTemperature", 120, train_data)
plot_smooth("Pulse", 100, train_data)
```


## Training a model

Recoding the continuous variables:

```{r}
nepal4 <- nepal3 |> 
  mutate(across(OralTemperature, ~ .x > 38.5),
         across(Pulse, ~ .x > 125))
```

Fitting a logistic model:

```{r}
model <- glm(BloodCSResult ~ ., binomial, nepal4)
```

Generating a clinical score from the model's coefficients:

```{r}
Xs <- nepal4[, -1]
cscore <- coef(model)[-1]
cscore <- as.numeric(cut(cscore, seq(floor(min(cscore)), ceiling(max(cscore)), .5))) |>
  setNames(names(Xs))
```

Computing the points from the clinical score:

```{r}
nepal5 <- tibble(observations = nepal4$BloodCSResult,
                 points       = colSums(t(as.matrix(Xs)) * pts))
```

```{r}
eps <- 1
the_points <- nepal5$points
the_thresholds <- (min(the_points) + eps):(max(the_points) - eps)
conf_mats <- map(the_thresholds, confusion_matrix)
```

```{r}
specificities <- map_dbl(conf_mats, specificity)
sensitivities <- map_dbl(conf_mats, sensitivity)

plot(1 - specificities, sensitivities, type = "l")
abline(0, 1)

(AUC <- .5 + sum(sensitivities + specificities - 1) / length(the_thresholds))
```




## Putting the code together for easy training

The function that computes the clinical scores (5 hyper-parameters):

```{r}
recoding <- function(x, temp, pulse) {
  mutate(x, across(OralTemperature, ~ .x > temp),                    # temp
            across(Pulse, ~ .x > pulse))                             # pulse
}
```

```{r}
make_clinical_scores0 <- function(x, temp, pulse, n, penalty, mixture = 0) {
# 1. recoding the 2 continuous variables:
  x <- mutate(x, across(OralTemperature, ~ .x > temp),               # temp
                 across(Pulse, ~ .x > pulse))                        # pulse
# 2. fitting a logistic model:
  model <- glmnet(model.matrix(BloodCSResult ~ ., x)[, -1], as.factor(x$BloodCSResult),
                  binomial, alpha = mixture, lambda = penalty)       # penalty, mixture
# 3. generating the clinical scores:
  coef2scores(coef(model)[-1, ], n)                                  # n
}
```

```{r}
make_clinical_scores <- function(x, n, penalty, mixture = 0) {
  model <- glmnet(model.matrix(BloodCSResult ~ ., x)[, -1], as.factor(x$BloodCSResult),
                  binomial, alpha = mixture, lambda = penalty)       # penalty, mixture
  coef2scores(coef(model)[-1, ], n)                                  # n
}
```

```{r}
train_data_recoded <- recoding(train_data, 38.5, 125)
cscore <- make_clinical_scores(train_data_recoded, 10, 1)
tibble(observations  = train_data$BloodCSResult,
       points        = make_points(train_data_recoded[, -1], cscore)) |> 
  mutate(predictions = points > 7) |> 
  select(-points) |> 
  table() |> 
  j_index()
```

```{r}
xvj <- function(train, validate, threshold, temp, pulse, n, penalty, mixture = 0) {
  train_recoded <- recoding(train, temp, pulse)                      # temp, pulse
  validate_recoded <- recoding(validate, temp, pulse)                # temp, pulse
  cscore <- make_clinical_scores(train_recoded, n, penalty, mixture) # n, penal, mixt
  tibble(observations  = validate$BloodCSResult,
         points        = make_points(validate_recoded[, -1], cscore)) |> 
    mutate(predictions = points > threshold) |>                      # threshold
    select(-points) |> 
    table() |> 
    j_index()
}
```

```{r}
cv_wrapper <- function(x, threshold, temp, pulse, n, penalty, mixture = 0, o = -9999) {
  map_dbl(x, ~ possibly(xvj, o)(train_data[.x, ], train_data[-.x, ],
                                    threshold, temp, pulse, n, penalty, mixture))
}
```

```{r}
trainings <- map(vfold_cv(train_data)$splits, ~ .x$in_id)
cv_wrapper(trainings, threshold = 7, temp = 38.5, pulse = 125, n = 10, penalty = 1)
```

About 20'

```{r}
the_grid2 <- expand.grid(threshold = seq(5, 30, 1), temp = seq(36, 40, .5),
                        pulse = seq(75, 150, 5), n = seq(5, 15, 5),
                        penalty = exp(seq(-4, 6)))

system.time(
jvals2 <- pmap(the_grid2, function(threshold, temp, pulse, n, penalty)
                          cv_wrapper(trainings, threshold, temp, pulse, n, penalty))
)
```

About 5:22':

```{r}
library(parallel)
system.time(
  jvals2 <- do.call(mcmapply,
          c(FUN = function(threshold, temp, pulse, n, penalty)
                    cv_wrapper(trainings, threshold, temp, pulse, n, penalty),
            as.list(mtcars),
            mc.cores = 11))
)
```

